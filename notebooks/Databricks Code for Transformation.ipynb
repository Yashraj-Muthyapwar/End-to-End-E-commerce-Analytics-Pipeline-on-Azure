{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2091dc29-d1f6-48bf-9847-26e6c3a8b7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a8fc222-413d-4faa-9fdf-c3e4115e412d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "storage_account = \"*********\"\n",
    "application_id = \"***********************\"\n",
    "directory_id = \"************************\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", \"************************\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b0b4677-457c-4339-9522-93a1ed4017e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "customer_df = spark.read.\\\n",
    "    format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"abfss://olistdata@*********.dfs.core.windows.net/Bronze/olist_customers_dataset.csv\")\n",
    "\n",
    "display(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70a2763-b6da-403e-8338-bd069e565aea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Access Azure Storage via External Location"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"abfss://olistdata@*********.dfs.core.windows.net/Bronze/\"\n",
    "orders_path = base_path + \"olist_orders_dataset.csv\"\n",
    "payments_path = base_path + \"olist_order_payments_dataset.csv\"\n",
    "items_path = base_path + \"olist_order_items_dataset.csv\"\n",
    "reviews_path = base_path + \"olist_order_reviews_dataset.csv\"\n",
    "customers_path = base_path + \"olist_customers_dataset.csv\"\n",
    "sellers_path = base_path + \"olist_sellers_dataset.csv\"\n",
    "# geolocation_path = base_path + \"olist_geolocation_dataset.csv\"\n",
    "products_path = base_path + \"olist_products_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30328ac2-40b7-4220-bf67-63ebfb4e2686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_df = spark.read.format(\"csv\").option(\"header\",True).load(orders_path)\n",
    "payments_df = spark.read.format(\"csv\").option(\"header\",True).load(payments_path)\n",
    "items_df = spark.read.format(\"csv\").option(\"header\",True).load(items_path)\n",
    "reviews_df = spark.read.format(\"csv\").option(\"header\",True).load(reviews_path)\n",
    "customers_df = spark.read.format(\"csv\").option(\"header\",True).load(customers_path)\n",
    "sellers_df = spark.read.format(\"csv\").option(\"header\",True).load(sellers_path)\n",
    "geolocation_df = spark.read.format(\"csv\").option(\"header\",True).load(geolocation_path)\n",
    "products_df = spark.read.format(\"csv\").option(\"header\",True).load(products_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9403c7f5-537d-4a32-aa1b-3302e60d20aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading Data from Pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ddca85d-954b-435b-99b3-802765b9bf08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# importing module\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "hostname = \"*********************\"\n",
    "database = \"************************\"\n",
    "port = \"*****\"\n",
    "username = \"************************\"\n",
    "password = \"************************\"\n",
    "\n",
    "uri = \"mongodb://\" + username + \":\" + password + \"@\" + hostname + \":\" + port + \"/\" + database\n",
    "\n",
    "# Connect with the portnumber and host\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Access database\n",
    "mydatabase = client[database]\n",
    "mydatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a731c0a-0afa-4e56-80b5-65c67194de75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection = mydatabase[\"product_categories\"]\n",
    "\n",
    "mongo_data = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71c463ab-43ac-4faf-b78e-3602294eced7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac68a098-87ae-4bd5-8a76-398b03bf397d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mongo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c4c64fd-05ee-47af-9bfa-af0cc6a55e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a6be63-95df-468a-bb19-65f530adda00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, datediff, current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73476d63-0802-4be3-b98e-35351ed6a4e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_datafram(df, name):\n",
    "    print(\"Cleaning \"+name)\n",
    "    return df.dropDuplicates().na.drop('all')\n",
    "\n",
    "orders_df = clean_datafram(orders_df, \"Orders\")\n",
    "display(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b90ca16-9bb5-4359-8485-ffa970f15336",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert Date Columns\n",
    "\n",
    "orders_df = orders_df.withColumn(\"order_purchase_timestamp\", to_date(col(\"order_purchase_timestamp\")))\\\n",
    ".withColumn(\"order_delivered_customer_date\", to_date(col(\"order_delivered_customer_date\")))\\\n",
    "    .withColumn(\"order_estimated_delivery_date\", to_date(col(\"order_estimated_delivery_date\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "badaa6ab-658a-4e33-ae24-b448fe2b5790",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769634068937}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Delivery and Time Delays\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "orders_df = orders_df.withColumn(\"actual_delivery_time\", datediff(col(\"order_delivered_customer_date\"), col(\"order_purchase_timestamp\")))\n",
    "orders_df = orders_df.withColumn(\"estimated_delivery_time\", datediff(col(\"order_estimated_delivery_date\"), col(\"order_purchase_timestamp\")))\n",
    "orders_df = orders_df.withColumn(\"Delay Time\", col(\"actual_delivery_time\") - col(\"estimated_delivery_time\"))\n",
    "\n",
    "display(orders_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "315128c5-96b5-4d91-9c24-770176c4d363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97dd2c15-2a9e-4e3c-a499-98c6c863c4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Join orders and customers\n",
    "orders_customers_df = orders_df.join(customers_df, \"customer_id\", \"left\")\n",
    "\n",
    "# 2. Join with payments (this fixes the Ambiguous Reference error)\n",
    "orders_payments_df = orders_customers_df.join(payments_df, \"order_id\", \"left\")\n",
    "\n",
    "# 3. Join with items\n",
    "orders_items_df = orders_payments_df.join(items_df, \"order_id\", \"left\")\n",
    "\n",
    "# 4. Join with products\n",
    "orders_items_products_df = orders_items_df.join(products_df, \"product_id\", \"left\")\n",
    "\n",
    "# 5. Join with sellers to get the final result\n",
    "final_df = orders_items_products_df.join(sellers_df, \"seller_id\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25012be9-4419-45b6-81cd-1377e6094f4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ded29f6-7c08-4c2f-98bf-cf97c5591cb3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 19"
    }
   },
   "outputs": [],
   "source": [
    "# Convert MongoDB ObjectId to string for Spark compatibility\n",
    "mongo_data['_id'] = mongo_data['_id'].astype(str)\n",
    "mongo_spark_df = spark.createDataFrame(mongo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78fe2687-21d8-4ab2-939e-907d02912f85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df = final_df.join(mongo_spark_df, \"product_category_name\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c65707-925a-4c55-9c59-881fbd5f7fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e2c62b-d744-4c20-bb19-61f799903bd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df.write.mode(\"overwrite\").parquet(\"abfss://olistdata@*********.dfs.core.windows.net/Silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e4fd3c9-a927-4411-b747-2a27deb71b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks Code for Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}